{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Methods 1\n",
    "### [Gerard Gorman](http://www.imperial.ac.uk/people/g.gorman), [Matthew Piggott](http://www.imperial.ac.uk/people/m.d.piggott), [Christian Jacobs](http://www.christianjacobs.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture ?: Numerical Linear Algebra I\n",
    "\n",
    "## Learning objectives:\n",
    "\n",
    "* Manipulation of matrices and matrix equations in Python.\n",
    "* Reminder on properties of matrices (from MM1): determinants, singularity etc.\n",
    "* Algorithms for the solution of linear systems (this week so-called direct methods).\n",
    "* Gaussian elimination, including back substitution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction - Linear (matrix) systems\n",
    "\n",
    "Recall from your Mathematical Methods I course that the we can re-write a system of simultaneous (linear) equations in matrix form.  For example, in week 4 of MM1 you considered the following example:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "  2x + 3y &=& 7 \\\\\n",
    "   x - 4y &=& 3\n",
    "\\end{eqnarray*} \n",
    "\n",
    "and it was noted that this can be written in matrix form as \n",
    "\n",
    "$$\n",
    "\\left(\n",
    "  \\begin{array}{rr}\n",
    "    2 & 3 \\\\\n",
    "    1 & -4  \\\\\n",
    "  \\end{array}\n",
    "\\right)\\left(\n",
    "  \\begin{array}{c}\n",
    "    x \\\\\n",
    "    y \\\\\n",
    "  \\end{array}\n",
    "\\right) = \\left(\n",
    "  \\begin{array}{c}\n",
    "    7 \\\\\n",
    "    3 \\\\\n",
    "  \\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "More generally, consider the arbitrary system of $m$ linear equations for $m$ unknowns\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "  A_{11}x_1 + A_{12}x_2 + \\dots + A_{1n}x_n &=& b_1 \\\\ \n",
    "  A_{21}x_1 + A_{22}x_2 + \\dots + A_{2n}x_n &=& b_2 \\\\ \n",
    "  \\vdots &=& \\vdots \\\\ \n",
    "  A_{n1}x_1 + A_{n2}x_2 + \\dots + A_{nn}x_n &=& b_n\n",
    "\\end{eqnarray*}\n",
    "\n",
    "where $A_{ij}$ are the constant coefficients of the linear system, $x_j$ are the unknown variables, and $b_i$\n",
    "are the terms on the right hand side (RHS).  Here the index $i$ is referring to the equation number\n",
    "(the row in the matrix below), with the index $j$ referring to the component of the unknown\n",
    "vector $\\pmb{x}$ (the column of the matrix).\n",
    "\n",
    "This system of equations can be represented as the matrix equation $A\\pmb{x}=\\pmb{b}$: \n",
    "\n",
    "$$\n",
    "\\left(\n",
    "  \\begin{array}{cccc}\n",
    "    A_{11} & A_{12} & \\dots & A_{1n} \\\\\n",
    "    A_{21} & A_{22} & \\dots & A_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    A_{n1} & A_{n2} & \\dots & A_{nn} \\\\\n",
    "  \\end{array}\n",
    "\\right)\\left(\n",
    "         \\begin{array}{c}\n",
    "           x_1 \\\\\n",
    "           x_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           x_n \\\\\n",
    "         \\end{array}\n",
    "       \\right)  = \\left(\n",
    "                   \\begin{array}{c}\n",
    "                     b_1 \\\\\n",
    "                     b_2 \\\\\n",
    "                     \\vdots \\\\\n",
    "                     b_n \\\\\n",
    "                   \\end{array}\n",
    "                 \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "For the above $2 \\times 2$ example of two equations in two unknowns in MM1 you substitution (multiply the second equation by 2 and subtract the first equation from the resulting equation to eliminate $x$ and hence allowing us to find $y$, we can then compute $x$ from the first equation) to easily give the solution \n",
    "\n",
    "$$ x=37/11, \\quad y=1/11.$$\n",
    "\n",
    "In MM1 you also considered $3 \\times 3$ examples which were a little more complicated but still doable.  This lecture considers the case of $n \\times n$ where $n$ could easily by billions! This case arises when you solve a differential equation numerically on a discrete mesh or grid. Here you would typically obtain one unknown and one (discrete, linear or nonlinear) equation at very grid point. You could generate an arbitrarily large matrix system simply by generating a finer and finer mesh.\n",
    "\n",
    "Note that you will solve differential equations numerically in the follow-up course Numerical Methods II.\n",
    "\n",
    "Cases where the matrix is non-square, i.e. of shape $m \\times n$ where $m\\ne n$ correspond to the (over- or under-determined) system where you have more or less equations than unknowns - we won't consider these in this lecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices in Python\n",
    "\n",
    "We have already used numpy arrays to store one-dimensional vectors of numbers.\n",
    "\n",
    "The convention is that these are generally considered to be *column* vectors and have shape $n \\times 1$.\n",
    "\n",
    "We can extend to higher dimensions through the more general concept of tensors: a vector can be\n",
    "represented as a one-dimensional array and is a 1st-order tensor;  a matrix is a two-dimensional array and us a 2nd-order tensor; and so on.\n",
    "\n",
    "Note that this is the total number of indices required to select each component of the array, i.e. we can identify each component of the vector $\\pmb{v}$ by $v_i$, and each component of the vector $A$ by\n",
    "$A_{ij}$.  \n",
    "\n",
    "Note that it is a convention that vectors are either underlined or bold, and generally lower case letters, whereas matrices are plain capital letters.\n",
    "\n",
    "Note that the terms *dimension*, *order*, *degree* and *rank* can all be used for this quantity, but beware that the word rank also has a different usage in the context of matrices and tensors!\n",
    "\n",
    "Here is an example of how we can extend our use of the numpy array object to two dimensions in order to define a matrix $A$ and some examples of some operations we can make on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.   2.   1.]\n",
      " [  6.   5.   4.]\n",
      " [  1.   4.   7.]]\n",
      "9\n",
      "2\n",
      "(3, 3)\n",
      "[[ 10.   6.   1.]\n",
      " [  2.   5.   4.]\n",
      " [  1.   4.   7.]]\n",
      "[[ 0.14285714 -0.07518797  0.02255639]\n",
      " [-0.28571429  0.51879699 -0.2556391 ]\n",
      " [ 0.14285714 -0.28571429  0.28571429]]\n",
      "133.00000000000003\n",
      "[[  1.00000000e+00   1.11022302e-16  -5.55111512e-17]\n",
      " [ -4.44089210e-16   1.00000000e+00   0.00000000e+00]\n",
      " [ -4.44089210e-16   6.66133815e-16   1.00000000e+00]]\n",
      "[[  1.00000000e+00   1.11022302e-16  -5.55111512e-17]\n",
      " [ -4.44089210e-16   1.00000000e+00   0.00000000e+00]\n",
      " [ -4.44089210e-16   6.66133815e-16   1.00000000e+00]]\n",
      "[[ 1.42857143 -0.15037594  0.02255639]\n",
      " [-1.71428571  2.59398496 -1.02255639]\n",
      " [ 0.14285714 -1.14285714  2.        ]]\n",
      "[ 0.  0.  0.]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from scipy import linalg\n",
    "A=numpy.array([[10., 2., 1.],[6., 5., 4.],[1., 4., 7.]])\n",
    "print(A)\n",
    "print(numpy.size(A))    # the total size of the array storing A - here 9 for a 3x3 matrix\n",
    "print(numpy.ndim(A))  # the dimension of the matrix A\n",
    "print(numpy.shape(A))  # the shape of the matrix A\n",
    "print(A.T)            # the transpose of the matrix A\n",
    "print(linalg.inv(A))  # the inverse of the matrix A - computed using a scipy algorithm\n",
    "print(linalg.det(A))  # the determinant of the matrix A - computed using a scipy algorithm\n",
    "print(numpy.dot(A,linalg.inv(A)))  # multiply A with its inverse using numpy's dot\n",
    "print(A.dot(linalg.inv(A)))  # same way to achieve the same thing\n",
    "print(A*linalg.inv(A))     # note that the * operator simply does operations element-wise\n",
    "\n",
    "print(numpy.zeros(3))  # how to initialise a vector of zeros \n",
    "print(numpy.zeros((3,3))) # how to initialise a matrix of zeros \n",
    "print(numpy.zeros((3,3,3)))  # how to initialise a 3rd-order tensor of zeros\n",
    "\n",
    "print(numpy.eye(3))  # how to initialise the identity matrix, I or Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly consider the $2 \\times 2$ case from MM1 recreated above where we claimed that $x=37/11$, $y=1/11$.  \n",
    "\n",
    "To solve the matrix equation \n",
    "\n",
    "$$ A\\pmb{x}=\\pmb{b} $$\n",
    "\n",
    "we can simply multiply both sides by the inverse of the matrix $A$ (if $A$ is invertible and if we know what the inverse is of course!):\n",
    "\n",
    "\\begin{align}\n",
    "A\\pmb{x} & = \\pmb{b}\\\\\n",
    "\\implies A^{-1}A\\pmb{x} & = A^{-1}\\pmb{b}\\\\\n",
    "\\implies I\\pmb{x} & = A^{-1}\\pmb{b}\\\\\n",
    "\\implies \\pmb{x} & = A^{-1}\\pmb{b}\n",
    "\\end{align}\n",
    "\n",
    "so we can find the solution $\\pmb{x}$ by multiplying the inverse of $A$ with the RHS vector $\\pmb{b}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.0\n",
      "[ 3.36363636  0.09090909]\n",
      "3.3636363636363638\n",
      "0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "A=numpy.array([[2., 3.],[1., -4.]])\n",
    "print(linalg.det(A))   # check first whether the determinant of A is non-zero - see below for reasons why!\n",
    "b=numpy.array([7., 3.])\n",
    "print(numpy.dot(linalg.inv(A),b))\n",
    "print(37./11.)\n",
    "print(1./11.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Aside: matrix objects </span>\n",
    "\n",
    "Note that numpy does possess a matrix object as a sub-class of the numpy array.  We can cast the above two-dimensional arrays into matrix objects and then the star operator does yield the expected matrix product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(type(A))  # the is an n-dimensional array (n-2 here)\n",
    "print(type(numpy.mat(A)))  # this casts the array A into the matrix class\n",
    "# for these objects * is standard matrix multuiplication and we can check that A*A^{-1}=I as expected\n",
    "print(numpy.mat(A)*numpy.mat(linalg.inv(A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Slicing </span>\n",
    "\n",
    "Note that just as for arrays or lists, we can use *slicing*  in order to extract components of matrices, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.   2.   1.]\n",
      " [  6.   5.   4.]\n",
      " [  1.   4.   7.]]\n",
      "2.0\n",
      "[ 10.   2.   1.]\n",
      "[ 1.  4.  7.]\n",
      "[ 2.  5.  4.]\n",
      "[[ 5.  4.]\n",
      " [ 4.  7.]]\n"
     ]
    }
   ],
   "source": [
    "A=numpy.array([[10., 2., 1.],[6., 5., 4.],[1., 4., 7.]])\n",
    "print(A)\n",
    "print(A[0,1])   # single entry, first row, second column\n",
    "print(A[0,:])   # first row\n",
    "print(A[-1,:])  # last row\n",
    "print(A[:,1])   # second column\n",
    "print(A[1:3,1:3]) # extract a 2x2 sub-matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of matrices: determinants, singularity, solvability of linear systems, etc\n",
    "\n",
    "Consider $N$ linear equations in $N$ unknowns, $A\\pmb{x}=\\pmb{b}$. \n",
    "\n",
    "From MM1 you learnt that this system has a *unique solution* provided that the determinant of A, $\\det(A)$, is non-zero. In this case the matrix is said to be *non-singular*.\n",
    "\n",
    "If $\\det(A)=0$ (with $A$ then termed a *singular matrix*), then the linear system does *not* have a unique solution, it may have either infinite *or* no solutions.\n",
    "\n",
    "For example, consider\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "  \\begin{array}{rr}\n",
    "    2 & 3 \\\\\n",
    "    4 & 6  \\\\\n",
    "  \\end{array}\n",
    "\\right)\\left(\n",
    "  \\begin{array}{c}\n",
    "    x \\\\\n",
    "    y \\\\\n",
    "  \\end{array}\n",
    "\\right) = \\left(\n",
    "  \\begin{array}{c}\n",
    "    4 \\\\\n",
    "    8 \\\\\n",
    "  \\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "The second equation is simply twice the first, and hence a solution to the first equation is also automatically a solution to the second equation. \n",
    "\n",
    "We hence only have one *linearly-independent* equation, and our problem is under-constrained: we effectively only have one eqution for two unknowns with infinitely many possibly solutions. \n",
    "\n",
    "If we replaced the RHS vector with $(4,7)^T$, then the two equations would be contradictory: in this case we have no solutions.\n",
    "\n",
    "Note that a set of vectors where one can be written as a linear sum of the others are termed *linearly-dependent*. When this is not the case the vectors are termed *linearly-independent*.\n",
    "\n",
    "The following properties of a square $n\\times n$ matrix are equivalent:\n",
    "\n",
    "* $\\det(A)\\ne 0$ - A is non-singular\n",
    "\n",
    "* The columns of $A$ are linearly independent\n",
    "\n",
    "* The rows of $A$ are linearly independent\n",
    "\n",
    "* The columns of A *span* $n$-dimensional space (recall MM1 - we can reach any point in $\\mathbb{R}^N$ through a linear combination of these vectors - note that this is simply what the operation $A\\pmb{x}$ is doing of course if you write it out)\n",
    "\n",
    "* $A$ is invertible, i.e. there exists a matrix $A^{-1}$ such that $A^{-1}A = A A^{-1}=I$\n",
    "\n",
    "* the matrix system $A\\pmb{x}=\\pmb{b}$ has a unique solution for every vector $b$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian elimination - method\n",
    "\n",
    "\n",
    "The Gaussian elimination algorithm is simply a systematic implementation of the method of equation substitution we used above to solve the $2\\times 2$ system (i.e. where we \"multiply the second equation by 2 and subtract the first equation from the resulting equation to *eliminate* $x$ and hence allowing us to find $y$, we can then compute $x$ from the first equation\").\n",
    "\n",
    "So *Gaussian elimination*  as the method is atributed to the mathematician *Gauss* (although it was certainly known before his time) and *elimination* as we seek to eliminate unknowns.\n",
    "\n",
    "To perform this method for arbitrarily large systems (on paper) we form the so-called augmented matrix\n",
    "\n",
    "$$\n",
    "[A|\\pmb{b}] = \n",
    "\\left[\n",
    "  \\begin{array}{rr|r}\n",
    "    2 & 3 & 7 \\\\\n",
    "    1 & -4 & 3  \\\\\n",
    "  \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "First we multiplied the second equation by 2, this yield the updated augmented matrix:\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "  \\begin{array}{rr|r}\n",
    "    2 & 3 & 7 \\\\\n",
    "    2 & -8 & 6 \\\\\n",
    "  \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "We can use the following notation to describe this operation:\n",
    "\n",
    "$$ Eq. (2) \\leftarrow 2\\times Eq. (2) $$\n",
    "\n",
    "Note importantly that this does not change anything about what these pair of equations are telling us about the unknown solution vector $\\pmb{x}$ which although it doesn't appear is implicilty defined by this augmented equation.\n",
    "\n",
    "The next step was to subtract the first equation from the updated second ($ Eq. (2) \\leftarrow Eq. (2) - Eq. (1) $):\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "  \\begin{array}{rr|r}\n",
    "    2 & 3 & 7 \\\\\n",
    "    0 & -11 & -1 \\\\\n",
    "  \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "The square matrix that is now in the $A$ position of this augmented system is an example of an *upper-triangular* matrix - all entries below the diagonal are zero.  For such a matrix we can perform back substitution - starting at the bottom to solve trivially for the final unknown ($y$ here which clearly takes the value $-1/-11$), and then using this knowledge working our way up to solve for each remaining unknown in turn, here just $x$ (solving $2x + 3\\times (1/11) = 7$).\n",
    "\n",
    "Note that we can perform the similar substitution if we had a lower triangular matrix, first finding the first unknown and then working our way forward through the remaining unknows - hence in this case *forward substitution*.\n",
    "\n",
    "Note that if we wished we could of course continue working on the augmented matrix to make the $A$ component diagonal: divide the second equation by 11 ($ Eq. (2) \\leftarrow (1/11)\\times Eq. (2) $) and add it to the first ($ Eq. (1) \\leftarrow Eq. (1) +  Eq. (2) $):\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "  \\begin{array}{rr|r}\n",
    "    2 & 0 & 7-3/11\\\\\n",
    "    0 & -1 & -1/11 \\\\\n",
    "  \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "and we can further make it the identity by dividing the rows by $2$ and $-1$ respectively ($ Eq. (1) \\leftarrow (1/2)\\times Eq. (1) $, $ Eq. (2) \\leftarrow (1/-1)\\times Eq. (2) $) :\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "  \\begin{array}{rr|r}\n",
    "    1 & 0 & (7-3/11)/2 \\\\\n",
    "    0 & 1 & 1/11 \\\\\n",
    "  \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Each of these augmented matrices encodes exactly the same information as the original matrix system in terms of the unknown vector $\\pmb{x}$, and hence this is telling us that\n",
    "\n",
    "$$ \\pmb{x} = I \\pmb{x} = \\left[\n",
    "  \\begin{array}{c}\n",
    "    (7-3/11)/2 \\\\\n",
    "    1/11 \\\\\n",
    "  \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "i.e. exactly the solution we found when we performed back substitution from the upper-triangular form of the augmented system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: Gaussian elimination $3 \\times 3$ example </span>\n",
    "\n",
    "Consider the system of linear equations\n",
    "\n",
    "\\begin{align*}\n",
    "  2x + 3y - 4z &= 10 \\\\\n",
    "  3x -  y + 2z &= 3 \\\\\n",
    "  4x + 2y + 2z &= 8\n",
    "\\end{align*}\n",
    "\n",
    "write this in matrix form, form the corresponding augmented system and perform row operations until you get to upper-triangular form, find the solution using back substitution.\n",
    "\n",
    "Write some code to check your answer using `numpy.dot(linalg.inv(A),b)`.\n",
    "\n",
    "You should find $x=43/23$, $y=24/23$, $z=-18/23$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian elimination - algorithm and code\n",
    "\n",
    "Note that we are free to perform the following operations on the augmented system without changing the corresponding solution:\n",
    "\n",
    "* Exchange two rows (refer to the section on *partial pivoting* next week)\n",
    "\n",
    "* Multiply a row by a non-zero constant ($Eq. (i)\\leftarrow \\lambda \\times Eq.(i)$)\n",
    "\n",
    "* Subtracting a (non-zero) multiple of one row with another ($Eq. (i)\\leftarrow Eq. (i) - \\lambda \\times Eq.(j)$)\n",
    "\n",
    "\n",
    "Note that the equation/row being subtracted is termed the *pivot*.\n",
    "\n",
    "\n",
    "Let's consider the algorithm mid-way working on an arbitrary matrix system, i.e. assume that the first $k$ rows (i.e. above the horizontal dashed line in the matrix below) have already been transformed into upper-triangular form, while the equations/rows below are not yet in this form.\n",
    "\n",
    "The augmented equation in this case can be assumed to look like\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "  \\begin{array}{rrrrrrrrr|r}\n",
    "    A_{11} & A_{12} & A_{13} & \\cdots & A_{1k} & \\cdots & A_{1j} & \\cdots & A_{1n} & b_1 \\\\\n",
    "    0      & A_{22} & A_{23} & \\cdots & A_{2k} & \\cdots & A_{2j} & \\cdots & A_{2n} & b_2 \\\\\n",
    "    0      & 0      & A_{33} & \\cdots & A_{3k} & \\cdots & A_{3j} & \\cdots & A_{3n} & b_3 \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "    0      & 0      & 0      & \\cdots & A_{kk} & \\cdots & A_{kj} & \\cdots & A_{kn} & b_k \\\\    \n",
    "\\hdashline\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "    0      & 0      & 0      & \\cdots & A_{ik} & \\cdots & A_{ij} & \\cdots & A_{in} & b_i \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "    0      & 0      & 0      & \\cdots & A_{nk} & \\cdots & A_{nj} & \\cdots & A_{nn} & b_n \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Remember that here as we are mid-way through the algorithm the $A$'s and $b$'s in the above are not the same as in the original system!\n",
    "\n",
    "Our aim as a next step in the algorithm is to use row $k$ (the pivot row) to *eliminate* $A_{ik}$, and we need to do this for all of the rows $i$ below the pivot, i.e. for all $i>k$.\n",
    "\n",
    "To eliminate $A_{ik}$ for a single row $i$ we need to perform the operation \n",
    "$$ Eq. (i)\\leftarrow Eq. (i) - \\frac{A_{ik}}{A_{kk}} \\times Eq.(k) $$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "\\begin{align}\n",
    "A_{ij} &\\leftarrow A_{ij} - \\frac{A_{ik}}{A_{kk}} A_{kj}, \\quad j=k,k+1,\\ldots,n\\\\\n",
    "b_i &\\leftarrow b_i - \\frac{A_{ik}}{A_{kk}} b_{k}\n",
    "\\end{align}\n",
    "\n",
    "$j$ only needs to run from $k$ upwards as we can assume that the earlier entries in column $i$ have already been set to zero, and also that the corresponding terms from the pivot row are also zero (we don't need to perform operations that we know involve the addition of zeros!).\n",
    "\n",
    "And to eliminate these entries for all rows below the pivot we need to repeat for all $i>k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: Gaussian elimination</span>\n",
    "\n",
    "Write some code that takes a matrix $A$ and a vector $\\pmb{b}$ and converts it into upper-triangular form using the above algorithm. For the $2 \\times 2$ and $3\\times 3$ examples from above compare the resulting $A$ and $\\pmb{b}$ you obtain following elimination.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back substitution\n",
    "\n",
    "Now that we have an augmented system in the upper-triangular form\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "  \\begin{array}{rrrrr|r}\n",
    "    A_{11} & A_{12} & A_{13} & \\cdots & A_{1n} &  b_1 \\\\\n",
    "    0      & A_{22} & A_{23} & \\cdots & A_{2n} &  b_2 \\\\\n",
    "    0      & 0      & A_{33} & \\cdots & A_{3n} &  b_3 \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "    0      & 0      & 0      & \\cdots & A_{nn} &  b_n \\\\    \n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "where the solution $\\pmb{x}$ of the original system also satisfies $A\\pmb{x}=\\pmb{b}$ for the $A$ and $\\pmb{b}$ in the above upper-triangular form (rather than the original $A$ and $\\pmb{b}$!).\n",
    "\n",
    "We can solve the final equation row to yield\n",
    "\n",
    "$$x_n = \\frac{b_n}{A_{nn}}$$\n",
    "\n",
    "The second to last equation then yields (note we've introduced a comma in the susbcripts here simply to make the more complex double indices easier to read)\n",
    "\n",
    "\\begin{align}\n",
    "A_{n-1,n-1}x_{n-1} + A_{n-1,n}x_n &= b_{n-1}\\\\\n",
    "\\implies x_{n-1} = \\frac{b_{n-1} - A_{n-1,n}x_n}{A_{n-1,n-1}}\\\\\n",
    "\\implies x_{n-1} = \\frac{b_{n-1} - A_{n-1,n}\\frac{b_n}{A_{nn}}}{A_{n-1,n-1}}\n",
    "\\end{align}\n",
    "\n",
    "and so on to row $k$ which yields\n",
    "\n",
    "\\begin{align}\n",
    "A_{k,k}x_{n,k} + A_{k,k+1}x_{n,k+1} +\\cdots +  A_{k,n}x_n &= b_{k}\\\\\n",
    "\\iff A_{k,k}x_{n,k} + \\sum_{j=k+1}^{n}A_{kj}x_j &= b_{k}\\\\\n",
    "\\implies x_{n,k} &= \\left( b_k - \\sum_{j=k+1}^{n}A_{kj}x_j\\right)\\frac{1}{A_{kk}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: Back substitution</span>\n",
    "\n",
    "Extend your code to perform back substitution and hence to obtain the final solution $\\pmb{x}$.  Check against the solutions found earlier.  Come up with some random $n\\times n$ matrices and check your code against `numpy.dot(linalg.inv(A),b)` (remember to use the original $A$ and $\\pmb{b}$ here of course!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gauss-Jordan elimination\n",
    "\n",
    "Recall that for the augmented matrix example we did by hand above we continued past the upper-triangular form so that the augmneted matrix had the identity matrix in the $A$ location. This algorithm has the name Gauss-Jordan elimination but note that it requires more operations than the conversion to upper-triangular form followed by back subsitution and so is only of academic interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Matrix inversion\n",
    "\n",
    "Note that if we were to form the augmented equation with the full identity matrix in the place of the vector $\\pmb{b}$, i.e. $[A|I]$ and performed row operations exactly as above until $A$ is transformed into the identity matrix $I$, then we would be left with the inverse of $A$ in the original $I$ location, i.e.\n",
    "\n",
    "$$ [A|I] \\rightarrow [I|A^{-1}] $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: Matrix inversion</span>\n",
    "\n",
    "Try updating your code to construct the inverse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: Zeros on the diagonal</span>\n",
    "\n",
    "You may have noticed above that we have no way of guaranteeing that the $A_{kk}$ we divide through by in the Guassian elimination or back substitution algorithms is non-zero (or not very small which will also lead to computational problems).\n",
    "Note also that we commented that we are free to exchange two rows in our augmented system - how could you use this fact to build robustness into our algorithms from matrices which do lead to very small or zero $A_{kk}$ values?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
